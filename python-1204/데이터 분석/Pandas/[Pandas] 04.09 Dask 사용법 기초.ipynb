{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "12cc63886cc14c86b1dec47c206acb50"
   },
   "source": [
    "# Dask 사용법 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "3e35a08138e94a1a8ea1d9d767cc321e"
   },
   "source": [
    "Pandas 는 데이터베이스나 CSV 파일의 데이터를 모두 메모리로 읽어들인 다음 메모리 위에서 데이터를 처리한다. 하지만 데이터의 양이 많은 경우에는 메모리의 제한으로 데이터프레임을 만들 수 없는 경우가 있다. 또한 데이터프레임의 크기가 너무 크면 질의나 그룹 연산을 할 때 하나의 CPU 코어로 처리하기에는 시간이 너무 많이 걸릴 수도 있다. \n",
    "\n",
    "이러한 경우에 도움이 되는 것이 Dask 패키지이다. Dask 패키지는 Pandas 데이터프레임 형식으로 빅데이터를 처리하기 위한 파이썬 패키지로 다음과 같은 두 가지 기능을 가진다.\n",
    "\n",
    "1. 가상 데이터프레임\n",
    "1. 병렬처리용 작업 스케줄러\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "a1e9d650979f4fe9ba0ae9002c4950f3"
   },
   "source": [
    "## 가상 데이터프레임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "fc3801258ac44660b7d4107b6652c15b"
   },
   "source": [
    "Dask 패키지를 사용하면 가상 데이터프레임을 만들 수 있다. 가상 데이터프레임은 Pandas 데이터프레임과 비슷한 기능을 제공하지만 실제로 모든 데이터가 메모리 상에 로드되어 있는 것이 아니라 하나 이상의 파일 혹은 데이터베이스에 존재하는 채로 처리할 수 있는 기능이다. 따라서 메모리 크기와 관계 없이 엄청나게 큰 CSV 파일을 가상 데이터프레임으로 로드하거나 같은 형식의 데이터를 가진 여러개의 CSV 파일을 하나의 가상 데이터프레임에 로드할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "13e69a886e1f493299411e8b2b5cce49"
   },
   "source": [
    "실제로 Dask의 가상 데이터프레임을 어떻게 쓸 수 있는지 실습을 통해 알아보자. 실습을 위해 홈 디렉토리 아래에 data라는 임시 디렉토리를 만들고 그곳으로 옮겨 CSV 파일을 하나 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "e7a0deb7588049fe885c311e5f394c85"
   },
   "outputs": [],
   "source": [
    "%%writefile data1.csv\n",
    "time,temperature,humidity\n",
    "0,22,58\n",
    "1,21,57\n",
    "2,25,57\n",
    "3,26,55\n",
    "4,22,53\n",
    "5,23,59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "9e426ccdbc7545269f20575112a402a2"
   },
   "source": [
    "Dask 패키지의 dataframe 서브패키지를 `dd`라는 이름으로 임포트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "ef46fca145c94879bd94ec6595278605"
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "c077ae3ded324215a7d23a20855aa583"
   },
   "source": [
    "`read_csv` 명령으로 데이터 파일 `data1.csv`에 대한 가상 데이터프레임 `df`를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "8973daaaef8d46b6ac7c89a6377c7137"
   },
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"data1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "414488b457e0448b80d459e1659e4986"
   },
   "source": [
    "`df`는 데이터프레임과 유사하지만 실제로 데이터를 메모리에 읽지 않았기 때문에 값은 표시되지 않는다.  \n",
    "\n",
    "`head`, `tail` 명령을 내리면 그 때서야 일부 데이터를 읽어서 표시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "56c287330f61432dadee31e6983910fe"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "4d0672fc19ac44d8a34dc266c237cb72"
   },
   "source": [
    "temperature 열의 평균을 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "1f081735c11c4dbcab18a5e65ac8715d"
   },
   "outputs": [],
   "source": [
    "df.temperature.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "7824c839f46a4fd392ca9a34ba745e21"
   },
   "source": [
    "데이터프레임과 달리 바로 결과가 나오지 않는다. 그 이유는 연산 반환값이 결과가 아닌 작업(task)이기 때문이다. 구체적으로 어떤 작업인지를 보려면 `visualize` 메서드를 사용하여 작업 그래프(graph)를 볼 수 있다. 작업 그래프란 이 계산을 하기 위해 실제로 CPU가 해야 할 일들의 순서도라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "088ebdc588304e58b2e5a573dcce7fe3"
   },
   "source": [
    "이 작업의 값을 실제로 구하려면 결과로 받은 작업 객체의 `compute` 메서드를 호출해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "e2cc46e3d83c402f9b72229101a96c7b"
   },
   "outputs": [],
   "source": [
    "df.temperature.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "01b4bc2d8fd448f2816a17a45ddc9aa6"
   },
   "source": [
    "이번에는 이 값을 화씨로 변환해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "00c0a58b619145deaf46fbc387dbd450"
   },
   "outputs": [],
   "source": [
    "(df.temperature * 9 / 5 + 32).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "1cc031b687d04afe917e45dce3e90047"
   },
   "source": [
    "이번에는 이 값으로 원래의 temperature 열을 갱신해보자. 이 때는 Pandas의 문법을 쓰지 못하고 다음과 같이 `assign` 메서드를 사용해야 한다. `assign` 메서드를 사용할 때는 `compute`를 할 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "cdceb6c0938d4bf8ad286cc8f2dbff58"
   },
   "outputs": [],
   "source": [
    "df = df.assign(temperature=df.temperature * 9 / 5 + 32)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "94e2b51ce6ba41538da6d4eddb106e65"
   },
   "source": [
    "자료형을 변환하거나 새로운 열을 추가하는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "ef8e37b3c9ba41a19c1bd22e90577756"
   },
   "outputs": [],
   "source": [
    "df = df.assign(title=df.temperature.astype(str) + \" degree\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "school_cell_uuid": "54d718ca3dac401288725a94b5ca6ae9"
   },
   "source": [
    "## 복수 데이터에 대한 가상 데이터프레임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "4dcbd28797694410aa007ca901349992"
   },
   "source": [
    "Dask의 가상 데이터프레임이므로 원천 데이터 파일을 하나가 아닌 복수로 설정할 수도 있다. 예를 들어 앞서 보았던 `data1.csv` 파일 이외에도 다음과 같이 `data2.csv', 'data3.csv` 파일이 있을 경우, 이 파일을 한 번에 하나의 데이터프레임으로 읽어들일 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "afcbe903529447ed9e55fe10aad4e734"
   },
   "outputs": [],
   "source": [
    "%%writefile data2.csv\n",
    "time,temperature,humidity\n",
    "0,22,58\n",
    "1,21,57\n",
    "2,25,57\n",
    "3,26,55\n",
    "4,22,53\n",
    "5,23,59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "8e57c1e9d1f84c1da6fb1e52e0f73aa4"
   },
   "outputs": [],
   "source": [
    "%%writefile data3.csv\n",
    "time,temperature,humidity\n",
    "0,22,58\n",
    "1,21,57\n",
    "2,25,57\n",
    "3,26,55\n",
    "4,22,53\n",
    "5,23,59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "2993d40974ad4a19a32dbc4f9c035634"
   },
   "source": [
    "복수 파일은 와일드카드(`*`) 기호를 이용하여 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "0f8be3a6cad24a568a229e0e80979ccb"
   },
   "outputs": [],
   "source": [
    "df = dd.read_csv('data*.csv')\n",
    "df.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "77feba673a4e47cbb0c42974e95da917"
   },
   "outputs": [],
   "source": [
    "df.temperature.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "school_cell_uuid": "8af5b8ef27f14304a348e5dade712b00"
   },
   "source": [
    "## 대량 데이터의 병렬 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "c1d8a9d50e714f4084bda52672fb59d9"
   },
   "source": [
    "이번에는 Dask로 대량의 데이터를 처리해보자. 샘플로 쓸 데이터는 미국 정부가 발표하는 공개 정보 중 하나로 시카고의 범죄 관련 데이터이다.\n",
    "\n",
    "* https://catalog.data.gov/dataset/crimes-2001-to-present-398a4\n",
    "\n",
    "다음 명령으로 이 데이터를 다운로드 받을 수 있다. CSV 파일의 크기가 1.3GB가 넘으므로 다운로드에 10분 이상이 걸릴 수도 있다.\n",
    "\n",
    "```\n",
    "!wget -O crime.csv https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
    "```\n",
    "\n",
    "파일을 다운로드 받은 후에는 가상 데이터프레임으로 읽어들인다. 구체적인 데이터를 아직 모르기 때문에 우선 문자열 자료형으로 읽어들인다. 또 `error_bad_lines` 옵션을 `False`로 해서 오류가 나는 데이터는 생략하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "15be7a08fe1e4ec28d80dd58eaaeb142"
   },
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"crime.csv\", dtype=str, error_bad_lines=False, warn_bad_lines=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "2bd9b63c2ebd4d5d81120452573c35d1"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "30109970ff214e6ea51944e2f59997e1"
   },
   "source": [
    "이제 이 데이터프레임으로 분석을 시작하자. 데이터의 크기가 큰 만큼 시간이 오래 걸리기 때문에 Dask는 작업 진행도를 알 수 있는 `ProgressBar`란 것을 제공한다. 다음과 같이 `ProgressBar`를 만들고 등록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "dbbfb1e1376a416997e1be2230aec5c8"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "68ef8ac71681440f859cb421382e9eb9"
   },
   "source": [
    "일단 등록하면 작업의 진행도를 프로그레스 바 형태로 알려준다. 우선 각 열의 데이터 갯수를 세어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "a2829fd8e19e4049a16679506e44ad2d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "7023730045b347ce94020da0067a3f34"
   },
   "source": [
    "각 열의 데이터 수를 세는 데만도 50초가 넘는 시간이 걸렸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "babacdf160dc4d6a95262d97e2abb1ca"
   },
   "source": [
    "Dask는 이러한 대량 데이터의 분석 작업을 돕기 위한 작업 스케줄러(task scheduler)라는 것을 제공한다. 작업 스케줄러는 하나의 작업을 여러개의 쓰레드, 프로세스, 노드 등이 나누어 분담하도록 한다.\n",
    "\n",
    "현재 Dask에서 제공하는 스케줄러의 종류는 다음과 같다.\n",
    "\n",
    "* dask.get: 단일 쓰레드 \n",
    "* dask.threaded.get: 멀티쓰레드 풀(pool)\n",
    "* dask.multiprocessing.get: 멀티프로세스 풀\n",
    "* distributed.Client.get: 여러대의 컴퓨터에서 분산 처리 \n",
    "\n",
    "병렬처리를 위해서는 어떠한 병렬 처리 방식을 사용할지, 작업 프로세스의 갯수는 어떻게 할지 등은 `compute` 명령에서 인수로 설정해야 한다. 다음 코드는 멀티프로세싱을 하고 4개의 CPU 코어를 동시에 사용하도록 설정한 예이다. (물론 이 코드가 실행되는 컴퓨터가 실제로 4개 이상의 코어를 가지고 있어야 성능이 개선된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "5eac53df48214893a1d47387e33b775c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.count().compute(scheduler='processes', num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "ec07bb1164cf4490a03bffe575e9ac21"
   },
   "source": [
    "이번에는 처리 속도가 3배 이상 빨라졌음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "school_cell_uuid": "fbaba476d91f4f6193fbdd9fd2399087"
   },
   "outputs": [],
   "source": [
    "!rm data?.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
